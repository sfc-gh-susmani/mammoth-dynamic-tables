{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üõ∞Ô∏è NGA Computer Vision Demo: Satellite Image Classification\n",
        "### GPU-Powered Image Analysis on Snowflake Container Runtime\n",
        "\n",
        "**National Geospatial-Intelligence Agency**  \n",
        "**Powered by:** Snowflake Container Runtime + GPU Acceleration + Open Source ML\n",
        "\n",
        "---\n",
        "\n",
        "## Demo Overview\n",
        "This notebook demonstrates:\n",
        "- üöÄ **GPU acceleration** on Snowflake Container Runtime\n",
        "- üî¨ **Computer vision** with open-source Python packages  \n",
        "- üõ∞Ô∏è **Satellite imagery analysis** for intelligence operations\n",
        "- üìä **Integration** with Snowflake data platform\n",
        "- ‚ö° **Real-time inference** on geospatial imagery\n",
        "\n",
        "## Quick Start Guide\n",
        "1. **Environment**: Ensure you're running on a GPU compute pool\n",
        "2. **External Access**: Enable ML packages integration in notebook settings\n",
        "3. **Data Access**: Verify connection to NGA imagery metadata tables\n",
        "4. **Execution**: Run cells sequentially for complete demo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for computer vision demo\n",
        "# Snowflake Container Runtime supports pip install for open-source packages\n",
        "%pip install torch torchvision transformers pillow requests matplotlib plotly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries and verify GPU availability\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "import time\n",
        "\n",
        "print(\"üöÄ Environment Setup\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Verify GPU availability  \n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üî• GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"‚úÖ Running on GPU - Optimal performance!\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"‚ö†Ô∏è  Running on CPU - Consider switching to GPU compute pool\")\n",
        "\n",
        "# Initialize Snowflake session\n",
        "session = get_active_session()\n",
        "print(f\"‚ùÑÔ∏è  Connected to Snowflake: {session.get_current_account()}\")\n",
        "print(\"‚úÖ Environment ready for computer vision demo!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained computer vision model\n",
        "print(\"ü§ñ Loading Computer Vision Model\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Use Microsoft ResNet-50 for image classification\n",
        "model_name = \"microsoft/resnet-50\"\n",
        "print(f\"üì• Downloading model: {model_name}\")\n",
        "\n",
        "# Load processor and model\n",
        "processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
        "\n",
        "# Move model to GPU if available  \n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "load_time = time.time() - start_time\n",
        "print(f\"‚úÖ Model loaded in {load_time:.2f} seconds\")\n",
        "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"üî• Running on: {device}\")\n",
        "print(\"üéØ Ready for satellite image classification!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query NGA imagery metadata from Snowflake\n",
        "print(\"üì° Connecting to NGA Imagery Database\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Query high-quality satellite images for analysis\n",
        "imagery_query = \"\"\"\n",
        "SELECT \n",
        "    image_id,\n",
        "    s3_key,\n",
        "    latitude,\n",
        "    longitude,\n",
        "    sensor_category,\n",
        "    combined_quality_score,\n",
        "    bay_region,\n",
        "    closest_landmark,\n",
        "    capture_date,\n",
        "    file_size_bytes\n",
        "FROM silver_imagery_metadata_iceberg \n",
        "WHERE s3_key IS NOT NULL \n",
        "    AND combined_quality_score >= 85\n",
        "ORDER BY combined_quality_score DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    imagery_df = session.sql(imagery_query).to_pandas()\n",
        "    print(f\"üõ∞Ô∏è  Found {len(imagery_df)} high-quality satellite images\")\n",
        "    print(f\"üìç Locations: {', '.join(imagery_df['BAY_REGION'].unique())}\")\n",
        "    print(f\"‚≠ê Average quality: {imagery_df['COMBINED_QUALITY_SCORE'].mean():.1f}%\")\n",
        "    \n",
        "    # Display sample data\n",
        "    print(\"\\nüìä Sample Imagery Metadata:\")\n",
        "    display(imagery_df[['IMAGE_ID', 'BAY_REGION', 'SENSOR_CATEGORY', 'COMBINED_QUALITY_SCORE']].head())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "    print(\"üí° Ensure you have access to silver_imagery_metadata_iceberg table\")\n",
        "    # Create sample data for demo purposes\n",
        "    imagery_df = pd.DataFrame({\n",
        "        'IMAGE_ID': ['demo_image_1', 'demo_image_2'],\n",
        "        'S3_KEY': ['sample1.jpg', 'sample2.jpg'],\n",
        "        'BAY_REGION': ['San Francisco', 'Oakland'],\n",
        "        'COMBINED_QUALITY_SCORE': [92.5, 89.1]\n",
        "    })\n",
        "    print(\"üîÑ Using sample data for demonstration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Computer Vision Analysis Function\n",
        "def analyze_satellite_image(s3_key, session, model, processor, device):\n",
        "    \"\"\"\n",
        "    GPU-accelerated computer vision analysis of satellite imagery\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get presigned URL for secure S3 access\n",
        "        url_query = f\"SELECT GET_PRESIGNED_URL('@s3_imagery_stage_direct', '{s3_key}', 3600) as url\"\n",
        "        url_result = session.sql(url_query).collect()\n",
        "        \n",
        "        if not url_result:\n",
        "            return None, \"Could not generate presigned URL\"\n",
        "            \n",
        "        image_url = url_result[0]['URL']\n",
        "        \n",
        "        # Download and process image\n",
        "        response = requests.get(image_url, timeout=30)\n",
        "        image = Image.open(io.BytesIO(response.content)).convert('RGB')\n",
        "        \n",
        "        # Preprocess image for model\n",
        "        inputs = processor(image, return_tensors=\"pt\").to(device)\n",
        "        \n",
        "        # GPU-accelerated inference\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        \n",
        "        inference_time = time.time() - start_time\n",
        "        \n",
        "        # Get top 5 predictions\n",
        "        top_predictions = torch.topk(predictions, 5)\n",
        "        \n",
        "        results = {\n",
        "            'image': image,\n",
        "            'predictions': [],\n",
        "            'inference_time': inference_time,\n",
        "            'device': str(device)\n",
        "        }\n",
        "        \n",
        "        # Convert to readable format\n",
        "        for score, idx in zip(top_predictions.values[0], top_predictions.indices[0]):\n",
        "            label = model.config.id2label[idx.item()]\n",
        "            confidence = score.item() * 100\n",
        "            results['predictions'].append({\n",
        "                'label': label,\n",
        "                'confidence': confidence\n",
        "            })\n",
        "        \n",
        "        return results, None\n",
        "        \n",
        "    except Exception as e:\n",
        "        return None, f\"Analysis error: {str(e)}\"\n",
        "\n",
        "print(\"üî¨ Computer vision analysis function ready!\")\n",
        "print(\"‚ö° Supports GPU-accelerated inference with secure S3 access\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU-Powered Computer Vision Demo\n",
        "print(\"üöÄ Starting GPU-Powered Satellite Image Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "analysis_results = []\n",
        "total_start_time = time.time()\n",
        "\n",
        "# Analyze first 3 images for demo\n",
        "for idx, row in imagery_df.head(3).iterrows():\n",
        "    print(f\"\\nüì° Analyzing Image {idx+1}\")\n",
        "    print(f\"  ID: {row['IMAGE_ID'][:30]}...\")\n",
        "    if 'BAY_REGION' in row:\n",
        "        print(f\"  Location: {row['BAY_REGION']}\")\n",
        "    if 'COMBINED_QUALITY_SCORE' in row:\n",
        "        print(f\"  Quality: {row['COMBINED_QUALITY_SCORE']:.1f}%\")\n",
        "    \n",
        "    # Perform analysis\n",
        "    results, error = analyze_satellite_image(\n",
        "        row['S3_KEY'], session, model, processor, device\n",
        "    )\n",
        "    \n",
        "    if results:\n",
        "        print(f\"  ‚ö° Inference: {results['inference_time']*1000:.1f}ms\")\n",
        "        print(f\"  üî• Device: {results['device']}\")\n",
        "        print(f\"  üéØ Top prediction: {results['predictions'][0]['label'][:30]}\")\n",
        "        print(f\"  üìä Confidence: {results['predictions'][0]['confidence']:.1f}%\")\n",
        "        \n",
        "        # Display visualization\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Show satellite image\n",
        "        ax1.imshow(results['image'])\n",
        "        ax1.set_title(f\"Satellite Image: {row.get('BAY_REGION', 'Unknown Location')}\")\n",
        "        ax1.axis('off')\n",
        "        \n",
        "        # Show prediction confidence\n",
        "        labels = [p['label'][:25] + ('...' if len(p['label']) > 25 else '') for p in results['predictions']]\n",
        "        confidences = [p['confidence'] for p in results['predictions']]\n",
        "        \n",
        "        bars = ax2.barh(labels[::-1], confidences[::-1], color='steelblue')\n",
        "        ax2.set_xlabel('Confidence (%)')\n",
        "        ax2.set_title('Computer Vision Predictions')\n",
        "        ax2.set_xlim(0, 100)\n",
        "        \n",
        "        # Add confidence labels\n",
        "        for bar, conf in zip(bars, confidences[::-1]):\n",
        "            ax2.text(conf + 1, bar.get_y() + bar.get_height()/2, \n",
        "                    f'{conf:.1f}%', va='center', fontsize=9)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Store results\n",
        "        analysis_results.append({\n",
        "            'image_id': row['IMAGE_ID'],\n",
        "            'location': row.get('BAY_REGION', 'Unknown'),\n",
        "            'top_prediction': results['predictions'][0]['label'],\n",
        "            'confidence': results['predictions'][0]['confidence'],\n",
        "            'inference_time_ms': results['inference_time'] * 1000,\n",
        "            'device': results['device']\n",
        "        })\n",
        "        \n",
        "    else:\n",
        "        print(f\"  ‚ùå Error: {error}\")\n",
        "\n",
        "total_time = time.time() - total_start_time\n",
        "print(f\"\\nüéØ Analysis Complete!\")\n",
        "print(f\"‚è±Ô∏è  Total time: {total_time:.2f} seconds\")\n",
        "\n",
        "if analysis_results:\n",
        "    avg_inference = np.mean([r['inference_time_ms'] for r in analysis_results])\n",
        "    print(f\"‚ö° Average inference: {avg_inference:.1f}ms\")\n",
        "    print(f\"üöÄ Throughput: {1000/avg_inference:.1f} images/second\")\n",
        "    print(f\"üéØ Average confidence: {np.mean([r['confidence'] for r in analysis_results]):.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo Summary & Performance Analytics\n",
        "print(\"üéØ NGA Computer Vision Demo Summary\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Platform information\n",
        "print(f\"üöÄ Platform: Snowflake Container Runtime\")\n",
        "print(f\"ü§ñ Model: {model_name}\")\n",
        "print(f\"üìä Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"‚ö° Device: {device} ({'GPU-Accelerated' if torch.cuda.is_available() else 'CPU'})\")\n",
        "\n",
        "if analysis_results:\n",
        "    # Convert to DataFrame for analysis\n",
        "    df_results = pd.DataFrame(analysis_results)\n",
        "    \n",
        "    print(f\"\\nüìà Performance Metrics:\")\n",
        "    print(f\"  Images Analyzed: {len(analysis_results)}\")\n",
        "    print(f\"  Average Inference: {df_results['inference_time_ms'].mean():.1f}ms\")\n",
        "    print(f\"  Throughput: {1000/df_results['inference_time_ms'].mean():.1f} images/sec\")\n",
        "    print(f\"  Average Confidence: {df_results['confidence'].mean():.1f}%\")\n",
        "    \n",
        "    # Interactive performance visualization\n",
        "    if len(df_results) > 1:\n",
        "        fig = go.Figure()\n",
        "        \n",
        "        # Performance chart\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=df_results['location'],\n",
        "            y=df_results['inference_time_ms'],\n",
        "            name='Inference Time (ms)',\n",
        "            marker_color='steelblue',\n",
        "            text=[f\"{x:.1f}ms\" for x in df_results['inference_time_ms']],\n",
        "            textposition='auto'\n",
        "        ))\n",
        "        \n",
        "        fig.update_layout(\n",
        "            title=\"üõ∞Ô∏è GPU Inference Performance by Location\",\n",
        "            xaxis_title=\"Location\",\n",
        "            yaxis_title=\"Inference Time (ms)\",\n",
        "            template=\"plotly_white\",\n",
        "            height=400\n",
        "        )\n",
        "        \n",
        "        fig.show()\n",
        "    \n",
        "    # Results table\n",
        "    print(f\"\\nüìä Detailed Results:\")\n",
        "    display(df_results[['location', 'top_prediction', 'confidence', 'inference_time_ms', 'device']])\n",
        "\n",
        "print(f\"\\nüèõÔ∏è  NGA Intelligence Capabilities Demonstrated:\")\n",
        "print(\"‚úÖ GPU-accelerated computer vision on satellite imagery\")\n",
        "print(\"‚úÖ Open-source ML libraries (PyTorch, Transformers)\")\n",
        "print(\"‚úÖ Real-time inference on high-resolution data\")\n",
        "print(\"‚úÖ Seamless Snowflake data platform integration\")\n",
        "print(\"‚úÖ Production-ready container runtime infrastructure\")\n",
        "\n",
        "print(f\"\\nüöÄ Next Steps for Production:\")\n",
        "print(\"‚Ä¢ Scale to thousands of satellite images\")\n",
        "print(\"‚Ä¢ Deploy custom models for specific intelligence tasks\")\n",
        "print(\"‚Ä¢ Implement real-time streaming inference pipelines\")\n",
        "print(\"‚Ä¢ Integrate with operational NGA intelligence workflows\")\n",
        "\n",
        "print(f\"\\nüéñÔ∏è  Mission-Ready Intelligence Platform: OPERATIONAL ‚úÖ\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
