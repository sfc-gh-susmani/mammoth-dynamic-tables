"""
NGA Imagery Intelligence Platform
Production-ready Streamlit in Snowflake application for geospatial intelligence analysis
Built for National Geospatial-Intelligence Agency
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import pydeck as pdk
import json
import requests
import uuid
from datetime import datetime, timedelta
from snowflake.snowpark.context import get_active_session
from snowflake.snowpark.functions import col

# Initialize Snowflake session
session = get_active_session()

# Configuration
STAGE_NAME = "@s3_imagery_stage_direct"  # Snowflake stage for S3 access

# App Configuration
st.set_page_config(
    page_title="NGA Imagery Intelligence Platform",
    page_icon="üõ∞Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for NGA-style professional appearance
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600;700&display=swap');
    
    /* NGA Color Palette */
    :root {
        --nga-navy: #1B365C;
        --nga-blue: #2E5C8A;
        --nga-light-blue: #4A7BA7;
        --nga-gold: #FDB515;
        --nga-light-gray: #F5F5F5;
        --nga-dark-gray: #2C2C2C;
        --nga-red: #D32F2F;
    }
    
    /* Override Streamlit default styling */
    .main .block-container {
        padding-top: 5rem;
        font-family: 'Open Sans', sans-serif;
    }
    
         /* Main header with NGA styling */
     .nga-main-header {
         background: linear-gradient(135deg, var(--nga-navy) 0%, var(--nga-blue) 100%);
         color: white;
         padding: 0;
         border-radius: 0.75rem;
         margin-bottom: 2rem;
         box-shadow: 0 8px 24px rgba(27, 54, 92, 0.4);
         text-align: center;
         border: 4px solid var(--nga-gold);
         position: relative;
         overflow: hidden;
     }
     
     .nga-main-header::before {
         content: '';
         position: absolute;
         top: 0;
         left: 0;
         right: 0;
         bottom: 0;
         background: linear-gradient(45deg, transparent 49%, rgba(253, 181, 21, 0.1) 50%, transparent 51%);
         pointer-events: none;
     }
    
    .nga-main-header h1 {
        font-size: 2.2rem;
        font-weight: 700;
        margin: 0;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .nga-main-header .subtitle {
        font-size: 1rem;
        opacity: 0.9;
        margin-top: 0.5rem;
        font-weight: 400;
    }
    
    /* NGA Logo container */
    .nga-logo-container {
        display: flex;
        align-items: center;
        justify-content: center;
        margin-bottom: 1rem;
    }
    
    .nga-logo-text {
        background: var(--nga-navy);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 0.25rem;
        font-weight: 700;
        font-size: 1.1rem;
        letter-spacing: 2px;
        border: 2px solid var(--nga-gold);
    }
    
    /* Enhanced metric cards with NGA styling */
    .nga-metric-card {
        background: linear-gradient(145deg, #ffffff 0%, #f8fafc 100%);
        padding: 1.2rem;
        border-radius: 0.5rem;
        border-left: 5px solid var(--nga-blue);
        margin: 0.5rem 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        transition: transform 0.2s ease;
    }
    
    .nga-metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    
    /* Status indicators */
    .status-operational { 
        color: #059669; 
        font-weight: 700; 
        text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
    }
    .status-warning { 
        color: var(--nga-gold); 
        font-weight: 700; 
        text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
    }
    
    /* Enhanced classification banner */
    .nga-classification-banner {
        background: linear-gradient(90deg, var(--nga-red) 0%, #B71C1C 100%);
        color: white;
        text-align: center;
        padding: 0.6rem;
        font-weight: 700;
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        z-index: 999;
        font-size: 0.9rem;
        letter-spacing: 1px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.3);
    }
    
    /* Sidebar styling */
    .css-1d391kg {
        background-color: var(--nga-light-gray);
    }
    
    /* Sidebar headers */
    .css-1d391kg h2 {
        color: var(--nga-navy);
        font-weight: 700;
        border-bottom: 2px solid var(--nga-gold);
        padding-bottom: 0.5rem;
    }
    
    /* Enhanced section headers */
    .nga-section-header {
        background: linear-gradient(135deg, var(--nga-light-blue) 0%, var(--nga-blue) 100%);
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 0.5rem;
        margin: 1rem 0 1.5rem 0;
        font-weight: 600;
        box-shadow: 0 2px 8px rgba(46, 92, 138, 0.3);
        border-left: 4px solid var(--nga-gold);
    }
    
    /* Quality legend styling */
    .nga-quality-legend {
        background: linear-gradient(145deg, #ffffff 0%, var(--nga-light-gray) 100%);
        padding: 1rem;
        border-radius: 0.5rem;
        border: 2px solid var(--nga-light-blue);
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .nga-quality-legend h4 {
        color: var(--nga-navy);
        margin-bottom: 0.5rem;
        font-weight: 700;
    }
    
    /* Info boxes */
    .nga-info-box {
        background: linear-gradient(145deg, #E3F2FD 0%, #BBDEFB 100%);
        border-left: 5px solid var(--nga-blue);
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        color: var(--nga-dark-gray);
        font-weight: 500;
    }
    
    /* Footer styling */
    .nga-footer {
        background: var(--nga-navy);
        color: white;
        text-align: center;
        padding: 1.5rem;
        margin-top: 3rem;
        border-radius: 0.5rem;
        border-top: 3px solid var(--nga-gold);
    }
    
    /* Metric styling improvements */
    div[data-testid="metric-container"] {
        background: linear-gradient(145deg, #ffffff 0%, #f8fafc 100%);
        border: 1px solid var(--nga-light-blue);
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }
    
    div[data-testid="metric-container"] > label {
        color: var(--nga-navy) !important;
        font-weight: 600 !important;
    }
    
    div[data-testid="metric-container"] > div {
        color: var(--nga-blue) !important;
        font-weight: 700 !important;
    }
</style>
""", unsafe_allow_html=True)

# NGA Classification Banner
st.markdown("""
<div class="nga-classification-banner">
    UNCLASSIFIED // FOR OFFICIAL USE ONLY
</div>
""", unsafe_allow_html=True)

# Add padding to account for classification banner
st.markdown("<div style='margin-top: 3rem;'></div>", unsafe_allow_html=True)

# Clean NGA Header - No Logo Complications
st.markdown("""
<div class="nga-main-header">
    <div style="text-align: center; padding: 2.5rem;">
        <div style="background: rgba(255,255,255,0.95); color: var(--nga-navy); padding: 1rem 2rem; border-radius: 0.5rem; margin-bottom: 1.5rem; font-weight: 700; font-size: 1.1rem; letter-spacing: 3px; border: 3px solid var(--nga-gold); display: inline-block; box-shadow: 0 6px 20px rgba(0,0,0,0.3);">
            NATIONAL GEOSPATIAL-INTELLIGENCE AGENCY
        </div>
        <h1 style="margin: 0; color: white; font-size: 2.8rem; font-weight: 700; text-shadow: 2px 2px 6px rgba(0,0,0,0.5); margin-bottom: 1rem;">
            üõ∞Ô∏è Imagery Intelligence Platform
        </h1>
        <div style="color: white; opacity: 0.95; font-size: 1.2rem; font-weight: 500; letter-spacing: 1px;">
            Advanced Geospatial Intelligence ‚Ä¢ Mission-Critical Analysis ‚Ä¢ Real-Time Operations
        </div>
    </div>
</div>
""", unsafe_allow_html=True)

# Core Data Retrieval Functions
@st.cache_data(ttl=300)  # Cache for 5 minutes
def get_imagery_metadata():
    """Retrieve comprehensive imagery metadata from silver layer"""
    query = """
    SELECT 
        image_id,
        capture_timestamp,
        capture_date,
        latitude,
        longitude,
        sensor_category,
        resolution_meters,
        file_size_bytes,
        file_url,
        s3_bucket,
        s3_key,
        data_quality_score,
        combined_quality_score,
        h3_res8_city,
        h3_res9_neighborhood,
        distance_to_sf_downtown_m,
        bay_region,
        within_5km_sf_downtown,
        closest_landmark,
        estimated_coverage_hectares,
        batch_id
    FROM silver_imagery_metadata_iceberg 
    ORDER BY capture_timestamp DESC
    LIMIT 1000
    """
    return session.sql(query).to_pandas()

@st.cache_data(ttl=300)
def get_spatial_metrics():
    """Retrieve spatial intelligence metrics"""
    query = """
    SELECT 
        image_id,
        capture_date,
        urban_classification,
        avg_distance_to_landmarks_m,
        quality_per_hectare_ratio,
        h3_coverage_category,
        latitude_decimal_places,
        longitude_decimal_places
    FROM silver_imagery_spatial_metrics_iceberg
    ORDER BY capture_date DESC
    LIMIT 1000
    """
    return session.sql(query).to_pandas()

@st.cache_data(ttl=300) 
def get_operational_summary():
    """Retrieve operational intelligence summary"""
    query = """
    SELECT 
        capture_date,
        bay_region,
        sensor_category,
        total_images,
        unique_h3_cells,
        avg_quality_score,
        total_coverage_hectares,
        spatial_diversity_index_pct,
        operational_effectiveness_score,
        images_within_5km_sf,
        ultra_high_res_count,
        high_res_count
    FROM gold_daily_summary_iceberg
    ORDER BY capture_date DESC
    LIMIT 100
    """
    return session.sql(query).to_pandas()

def get_s3_presigned_url(s3_key):
    """Generate pre-signed URL for S3 image access using Snowflake GET_PRESIGNED_URL"""
    try:
        # Use Snowflake's GET_PRESIGNED_URL with our configured stage
        query = f"SELECT GET_PRESIGNED_URL('@s3_imagery_stage_direct', '{s3_key}', 3600) as presigned_url"
        result = session.sql(query).collect()
        
        if result and len(result) > 0:
            return result[0]['PRESIGNED_URL']
        else:
            return None
    except Exception as e:
        st.error(f"Error generating presigned URL: {str(e)}")
        return None

def display_image_from_s3(s3_key, caption="Satellite Image"):
    """Display image from S3 using Snowflake presigned URLs"""
    try:
        presigned_url = get_s3_presigned_url(s3_key)
        if presigned_url:
            st.image(presigned_url, caption=caption, use_column_width=True)
            with st.expander("üîó Image Details"):
                st.write(f"**S3 Key:** {s3_key}")
                st.write(f"**Secure Access:** Presigned URL (1 hour expiry)")
        else:
            st.warning(f"Unable to generate presigned URL for: {s3_key}")
    except Exception as e:
        st.error(f"Error displaying image: {str(e)}")
        st.info(f"Image reference: {s3_key}")

# NGA Sidebar Navigation
st.sidebar.markdown("""
<div style="background: linear-gradient(135deg, var(--nga-navy) 0%, var(--nga-blue) 100%); 
           color: white; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem; 
           text-align: center; border-left: 4px solid var(--nga-gold);">
    <h2 style="margin: 0; color: white;">üéØ NGA Mission Control</h2>
    <small style="opacity: 0.9;">Intelligence Operations Center</small>
</div>
""", unsafe_allow_html=True)

page = st.sidebar.selectbox(
    "Select Intelligence Module",
    ["üè† Operational Dashboard", "üõ∞Ô∏è Imagery Viewer", "üó∫Ô∏è Geospatial Analysis", "‚öì Maritime Intelligence", "ü§ñ AI Intelligence Assistant", "üìä Intelligence Reports"]
)

# NGA Sidebar Filters
st.sidebar.markdown("""
<div style="background: var(--nga-light-blue); color: white; padding: 0.8rem; 
           border-radius: 0.5rem; margin: 1rem 0; text-align: center; 
           border-left: 4px solid var(--nga-gold);">
    <h3 style="margin: 0; color: white;">üîç Intelligence Filters</h3>
</div>
""", unsafe_allow_html=True)

# Load data
with st.spinner("Loading intelligence data..."):
    imagery_df = get_imagery_metadata()
    spatial_df = get_spatial_metrics()
    summary_df = get_operational_summary()

# Common filters
# Convert pandas Timestamps to datetime.date objects for the date_input widget
if not imagery_df.empty and 'CAPTURE_DATE' in imagery_df.columns:
    # Ensure CAPTURE_DATE is datetime type and handle any invalid dates
    imagery_df['CAPTURE_DATE'] = pd.to_datetime(imagery_df['CAPTURE_DATE'], errors='coerce')
    
    # Remove any rows with invalid dates
    imagery_df = imagery_df.dropna(subset=['CAPTURE_DATE'])
    
    if not imagery_df.empty:
        min_date = imagery_df['CAPTURE_DATE'].min().date()
        max_date = imagery_df['CAPTURE_DATE'].max().date()
    else:
        # Fallback to current date if no valid data
        from datetime import date
        min_date = max_date = date.today()
else:
    # Fallback to current date if no data
    from datetime import date
    min_date = max_date = date.today()

date_range = st.sidebar.date_input(
    "Date Range",
    value=(min_date, max_date),
    min_value=min_date,
    max_value=max_date
)

sensor_filter = st.sidebar.multiselect(
    "Sensor Platforms",
    options=imagery_df['SENSOR_CATEGORY'].unique(),
    default=imagery_df['SENSOR_CATEGORY'].unique()[:3]
)

quality_threshold = st.sidebar.slider(
    "Minimum Quality Score",
    min_value=0.0,
    max_value=100.0,
    value=80.0,
    step=5.0
)

# Filter data based on selections
try:
    # Ensure we have valid date_range values
    if isinstance(date_range, tuple) and len(date_range) >= 2 and date_range[0] is not None and date_range[1] is not None:
        # Convert date_range to proper pandas Timestamps to avoid comparison issues
        start_date = pd.Timestamp(date_range[0])
        end_date = pd.Timestamp(date_range[1]) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)  # Include full end date
        
        # Apply all filters
        filtered_df = imagery_df[
            (imagery_df['CAPTURE_DATE'] >= start_date) &
            (imagery_df['CAPTURE_DATE'] <= end_date) &
            (imagery_df['SENSOR_CATEGORY'].isin(sensor_filter)) &
            (imagery_df['COMBINED_QUALITY_SCORE'] >= quality_threshold)
        ].reset_index(drop=True)
    else:
        # If date_range is invalid, just filter by other criteria
        filtered_df = imagery_df[
            (imagery_df['SENSOR_CATEGORY'].isin(sensor_filter)) &
            (imagery_df['COMBINED_QUALITY_SCORE'] >= quality_threshold)
        ].reset_index(drop=True)
        
except Exception as e:
    st.error(f"Error filtering data: {str(e)}")
    # Fallback to unfiltered data
    filtered_df = imagery_df.copy()

# PAGE ROUTING
if page == "üè† Operational Dashboard":
    st.subheader("üìà Operational Intelligence Overview")
    
    # Key Metrics Row
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        total_images = len(filtered_df)
        st.metric("Total Images", f"{total_images:,}")
    
    with col2:
        unique_h3 = filtered_df['H3_RES8_CITY'].nunique()
        st.metric("H3 Cells Covered", f"{unique_h3:,}")
    
    with col3:
        avg_quality = filtered_df['COMBINED_QUALITY_SCORE'].mean()
        st.metric("Avg Quality Score", f"{avg_quality:.1f}%")
    
    with col4:
        total_coverage = filtered_df['ESTIMATED_COVERAGE_HECTARES'].sum()
        st.metric("Total Coverage", f"{total_coverage:.1f} ha")
    
    with col5:
        high_quality_pct = (filtered_df['COMBINED_QUALITY_SCORE'] >= 90).mean() * 100
        st.metric("High Quality %", f"{high_quality_pct:.1f}%")
    
    # System Status with NGA styling
    st.markdown("""
    <div class="nga-section-header">
        üî¥ NGA Intelligence System Status
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="nga-metric-card">
            <h4 style="color: var(--nga-navy); margin-bottom: 0.5rem;">üì° Data Pipeline</h4>
            <span class="status-operational">‚óè OPERATIONAL</span><br>
            <strong>Last Update:</strong> {} images processed<br>
            <small style="color: var(--nga-blue);">Real-time ingestion active</small>
        </div>
        """.format(len(imagery_df)), unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="nga-metric-card">
            <h4 style="color: var(--nga-navy); margin-bottom: 0.5rem;">‚òÅÔ∏è S3 Intelligence Storage</h4>
            <span class="status-operational">‚óè OPERATIONAL</span><br>
            <strong>Total Files:</strong> {} images stored<br>
            <small style="color: var(--nga-blue);">Secure cloud infrastructure</small>
        </div>
        """.format(len(imagery_df)), unsafe_allow_html=True)
    
    # Recent Activity Chart
    st.subheader("üìä Recent Collection Activity")
    daily_stats = filtered_df.groupby('CAPTURE_DATE').agg({
        'IMAGE_ID': 'count',
        'COMBINED_QUALITY_SCORE': 'mean',
        'ESTIMATED_COVERAGE_HECTARES': 'sum'
    }).reset_index()
    
    fig = px.bar(daily_stats, x='CAPTURE_DATE', y='IMAGE_ID', 
                 title="Daily Image Collection Volume",
                 labels={'IMAGE_ID': 'Images Collected', 'CAPTURE_DATE': 'Date'})
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)

elif page == "üõ∞Ô∏è Imagery Viewer":
    st.subheader("üõ∞Ô∏è Satellite Imagery Viewer")
    st.markdown("**View satellite image locations on the map and select an image below to view details**")
    
    # Direct query approach like your H3 example
    query = """
    SELECT
        IMAGE_ID,
        CAPTURE_TIMESTAMP,
        CAPTURE_DATE,
        LATITUDE,
        LONGITUDE,
        SENSOR_CATEGORY,
        BAY_REGION,
        RESOLUTION_CATEGORY,
        COMBINED_QUALITY_SCORE,
        RESOLUTION_METERS,
        S3_KEY
    FROM MAMMOTH.PUBLIC.SILVER_IMAGERY_METADATA_ICEBERG
    WHERE LATITUDE IS NOT NULL 
      AND LONGITUDE IS NOT NULL
      AND LATITUDE BETWEEN -90 AND 90
      AND LONGITUDE BETWEEN -180 AND 180
    LIMIT 100;
    """
    
    df = session.sql(query).to_pandas()
    
    if not df.empty:
        # Prepare data for pydeck (following your working pattern)
        point_data = []
        for _, row in df.iterrows():
            point_data.append({
                "position": [float(row["LONGITUDE"]), float(row["LATITUDE"])],
                "IMAGE_ID": str(row["IMAGE_ID"]),
                "CAPTURE_TIMESTAMP": str(row["CAPTURE_TIMESTAMP"]),
                "CAPTURE_DATE": str(row["CAPTURE_DATE"]),
                "LATITUDE": row["LATITUDE"],
                "LONGITUDE": row["LONGITUDE"],
                "SENSOR_CATEGORY": str(row["SENSOR_CATEGORY"]),
                "BAY_REGION": str(row["BAY_REGION"]),
                "RESOLUTION_CATEGORY": str(row["RESOLUTION_CATEGORY"]),
                "COMBINED_QUALITY_SCORE": row["COMBINED_QUALITY_SCORE"],
                "RESOLUTION_METERS": row["RESOLUTION_METERS"],
                "S3_KEY": str(row["S3_KEY"])
            })
        
        layer = pdk.Layer(
            "ScatterplotLayer",
            data=point_data,
            get_position="position",
            get_color=[0, 128, 255, 120],  # Using your blue color
            get_radius=200,
            radius_scale=1,
            pickable=True,
        )
        
        view_state = pdk.ViewState(latitude=37.77, longitude=-122.42, zoom=9)
        
        tooltip_html = """
        <b>üõ∞Ô∏è Satellite Image</b><br>
        <b>Sensor:</b> {SENSOR_CATEGORY}<br>
        <b>Capture Date:</b> {CAPTURE_DATE}<br>
        <b>Lat:</b> {LATITUDE}, <b>Lon:</b> {LONGITUDE}<br>
        <b>Quality:</b> {COMBINED_QUALITY_SCORE}%<br>
        <b>Bay Region:</b> {BAY_REGION}<br>
        <b>Resolution:</b> {RESOLUTION_CATEGORY}
        """
        
        # Display the map
        st.pydeck_chart(pdk.Deck(
            layers=[layer],
            initial_view_state=view_state,
            tooltip={"html": tooltip_html, "style": {"backgroundColor": "steelblue", "color": "white"}}
        ))
        
        # Image selection below the map
        st.markdown("---")
        st.subheader("üñºÔ∏è Select Satellite Image")
        
        # Create a selectbox with image options
        image_options = []
        for idx, row in df.iterrows():
            label = f"{row['SENSOR_CATEGORY']} - {row['CAPTURE_DATE']} - Quality: {row['COMBINED_QUALITY_SCORE']:.1f}% - {row['BAY_REGION']}"
            image_options.append((label, idx))
        
        if image_options:
            selected_label, selected_idx = st.selectbox(
                "Select an image to view:",
                image_options,
                format_func=lambda x: x[0],
                index=0
            )
            
            selected_image = df.iloc[selected_idx]
            
            # Display selected image details and image
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.markdown(f"""
                **üìã Image Intelligence:**
                - **ID:** {selected_image['IMAGE_ID']}
                - **Sensor:** {selected_image['SENSOR_CATEGORY']}
                - **Quality Score:** {selected_image['COMBINED_QUALITY_SCORE']:.1f}%
                - **Resolution:** {selected_image['RESOLUTION_METERS']}m
                - **Capture Date:** {selected_image['CAPTURE_DATE']}
                - **Location:** {selected_image['BAY_REGION']}
                - **Coordinates:** {selected_image['LATITUDE']:.6f}, {selected_image['LONGITUDE']:.6f}
                """)
            
            with col2:
                # Display the actual satellite image
                if pd.notna(selected_image['S3_KEY']):
                    display_image_from_s3(
                        selected_image['S3_KEY'], 
                        caption=f"Satellite Image - {selected_image['SENSOR_CATEGORY']} - {selected_image['CAPTURE_DATE']}"
                    )
                else:
                    st.warning("No satellite image available for this location")
        else:
            st.warning("No images available for selection")
    else:
        st.error("No imagery data found in the database")

elif page == "üó∫Ô∏è Geospatial Analysis":
    st.subheader("üó∫Ô∏è Geospatial Intelligence Analysis")
    
    # Data diagnostics
    with st.expander("üìä Data Diagnostics", expanded=False):
        st.write(f"**Total records loaded:** {len(imagery_df)}")
        st.write(f"**Records after filtering:** {len(filtered_df)}")
        if not filtered_df.empty:
            st.write(f"**Coordinate columns available:** {['LATITUDE', 'LONGITUDE'] if all(col in filtered_df.columns for col in ['LATITUDE', 'LONGITUDE']) else 'Missing coordinate columns'}")
            if 'LATITUDE' in filtered_df.columns and 'LONGITUDE' in filtered_df.columns:
                valid_coords = filtered_df.dropna(subset=['LATITUDE', 'LONGITUDE'])
                st.write(f"**Records with valid coordinates:** {len(valid_coords)}")
                if not valid_coords.empty:
                    st.write(f"**Latitude range:** {valid_coords['LATITUDE'].min():.4f} to {valid_coords['LATITUDE'].max():.4f}")
                    st.write(f"**Longitude range:** {valid_coords['LONGITUDE'].min():.4f} to {valid_coords['LONGITUDE'].max():.4f}")
        else:
            st.write("**No data available after filtering**")
    
    # Map Display
    st.subheader("üìç Imagery Locations Map")
    
    # Check if we have data to display
    if not filtered_df.empty and 'LATITUDE' in filtered_df.columns and 'LONGITUDE' in filtered_df.columns:
        # Remove rows with invalid coordinates
        valid_coords_df = filtered_df.dropna(subset=['LATITUDE', 'LONGITUDE'])
        valid_coords_df = valid_coords_df[
            (valid_coords_df['LATITUDE'].between(-90, 90)) & 
            (valid_coords_df['LONGITUDE'].between(-180, 180))
        ]
        
        if not valid_coords_df.empty:
            # Create map centered on San Francisco Bay Area or data center
            center_lat = valid_coords_df['LATITUDE'].mean()
            center_lon = valid_coords_df['LONGITUDE'].mean()
            
            # Use a reasonable default if coordinates are still invalid
            if pd.isna(center_lat) or pd.isna(center_lon):
                center_lat, center_lon = 37.7749, -122.4194  # San Francisco default
            
            # Sample data for map (limit for performance)
            map_data = valid_coords_df.head(100)[['LATITUDE', 'LONGITUDE', 'COMBINED_QUALITY_SCORE', 'SENSOR_CATEGORY']].copy()
            map_data.columns = ['lat', 'lon', 'quality', 'sensor']
            
            # Ensure quality scores are numeric
            map_data['quality'] = pd.to_numeric(map_data['quality'], errors='coerce')
            map_data = map_data.dropna(subset=['quality'])
            
            if not map_data.empty:
                st.info(f"Displaying {len(map_data)} satellite imagery collection points")
                
                try:
                    # Prepare data for pydeck
                    map_data['elevation'] = map_data['quality'] * 10  # Height based on quality
                    
                    # Define color mapping based on quality score
                    def get_color(quality):
                        if quality >= 90:
                            return [0, 255, 0, 160]  # Green for excellent
                        elif quality >= 80:
                            return [154, 205, 50, 160]  # Yellow-green for good
                        elif quality >= 70:
                            return [255, 255, 0, 160]  # Yellow for fair
                        elif quality >= 60:
                            return [255, 165, 0, 160]  # Orange for poor
                        else:
                            return [255, 0, 0, 160]  # Red for very poor
                    
                    # Add color column
                    map_data['color'] = map_data['quality'].apply(get_color)
                    
                    # Calculate optimal center based on data distribution
                    # Use median for better centering on main cluster
                    optimal_lat = map_data['lat'].median()
                    optimal_lon = map_data['lon'].median()
                    
                    # Calculate appropriate zoom level based on data spread
                    lat_range = map_data['lat'].max() - map_data['lat'].min()
                    lon_range = map_data['lon'].max() - map_data['lon'].min()
                    
                    # Determine zoom level based on coordinate range
                    if max(lat_range, lon_range) > 1.0:
                        zoom_level = 8
                    elif max(lat_range, lon_range) > 0.5:
                        zoom_level = 9
                    elif max(lat_range, lon_range) > 0.2:
                        zoom_level = 10
                    elif max(lat_range, lon_range) > 0.1:
                        zoom_level = 11
                    else:
                        zoom_level = 12
                    
                    # Create the pydeck chart
                    st.pydeck_chart(pdk.Deck(
                        map_style='mapbox://styles/mapbox/light-v9',
                        initial_view_state=pdk.ViewState(
                            latitude=optimal_lat,
                            longitude=optimal_lon,
                            zoom=zoom_level,
                            pitch=45
                        ),
                        layers=[
                            # Scatter plot layer for imagery points
                            pdk.Layer(
                                'ScatterplotLayer',
                                data=map_data,
                                get_position=['lon', 'lat'],
                                get_color='color',
                                get_radius='quality',
                                radius_scale=100,
                                radius_min_pixels=8,
                                radius_max_pixels=25,
                                pickable=True,
                                tooltip={
                                    "html": "<b>üõ∞Ô∏è Satellite Imagery</b><br/>"
                                           "<b>Sensor:</b> {sensor}<br/>"
                                           "<b>Quality:</b> {quality:.1f}%<br/>"
                                           "<b>Location:</b> {lat:.4f}, {lon:.4f}",
                                    "style": {
                                        "backgroundColor": "steelblue",
                                        "color": "white"
                                    }
                                }
                            ),
                            # Column layer for 3D effect based on quality
                            pdk.Layer(
                                'ColumnLayer',
                                data=map_data,
                                get_position=['lon', 'lat'],
                                get_elevation='elevation',
                                elevation_scale=50,
                                get_fill_color='color',
                                radius=50,
                                pickable=True,
                                auto_highlight=True,
                                tooltip={
                                    "html": "<b>üõ∞Ô∏è Quality Indicator</b><br/>"
                                           "<b>Quality Score:</b> {quality:.1f}%<br/>"
                                           "<b>Sensor:</b> {sensor}",
                                    "style": {
                                        "backgroundColor": "steelblue",
                                        "color": "white"
                                    }
                                }
                            )
                        ],
                    ))
                    
                    # Add quality score legend with NGA styling
                    st.markdown("""
                    <div class="nga-quality-legend">
                        <h4>üéØ NGA Intelligence Quality Score Legend</h4>
                        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 0.5rem;">
                            <div style="padding: 0.3rem; border-left: 4px solid #00ff00;"><strong>üü¢ Excellent:</strong> 90-100%</div>
                            <div style="padding: 0.3rem; border-left: 4px solid #9acd32;"><strong>üü° Good:</strong> 80-89%</div>
                            <div style="padding: 0.3rem; border-left: 4px solid #ffff00;"><strong>üü° Fair:</strong> 70-79%</div>
                            <div style="padding: 0.3rem; border-left: 4px solid #ffa500;"><strong>üü† Poor:</strong> 60-69%</div>
                            <div style="padding: 0.3rem; border-left: 4px solid #ff0000;"><strong>üî¥ Critical:</strong> <60%</div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Add summary statistics
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        excellent_count = (map_data['quality'] >= 90).sum()
                        st.metric("üü¢ Excellent", excellent_count)
                    with col2:
                        good_count = ((map_data['quality'] >= 80) & (map_data['quality'] < 90)).sum()
                        st.metric("üü° Good", good_count)
                    with col3:
                        fair_count = ((map_data['quality'] >= 70) & (map_data['quality'] < 80)).sum()
                        st.metric("üü† Fair", fair_count)
                    with col4:
                        poor_count = (map_data['quality'] < 70).sum()
                        st.metric("üî¥ Poor", poor_count)
                    
                    # Additional insights with NGA styling
                    avg_quality = map_data['quality'].mean()
                    st.markdown(f"""
                    <div class="nga-info-box">
                        <strong>üìä NGA Intelligence Summary:</strong><br>
                        <strong>Average Quality Score:</strong> {avg_quality:.1f}% | 
                        <strong>Total Collection Points:</strong> {len(map_data)} | 
                        <strong>Area of Operations:</strong> San Francisco Bay Area<br>
                        <small>Real-time geospatial intelligence for mission-critical operations</small>
                    </div>
                    """, unsafe_allow_html=True)
                    
                except Exception as e:
                    st.error(f"Error creating map visualization: {str(e)}")
                    st.info("Try adjusting your filters to include more data points.")
                    # Fallback to simple streamlit map
                    st.markdown("**Fallback Map View:**")
                    st.map(map_data[['lat', 'lon']])
            else:
                st.warning("No valid coordinate data available for mapping after filtering.")
        else:
            st.warning("No imagery data with valid coordinates found. Please adjust your filters.")
    else:
        st.warning("No imagery data available for mapping. Please check your data sources.")
    
    # H3 Analysis
    st.subheader("üî¨ H3 Spatial Intelligence")
    
    if not filtered_df.empty:
        col1, col2 = st.columns(2)
        
        with col1:
            try:
                if 'H3_RES8_CITY' in filtered_df.columns:
                    h3_coverage = filtered_df['H3_RES8_CITY'].value_counts().head(10)
                    if not h3_coverage.empty:
                        fig = px.bar(
                            x=h3_coverage.values,
                            y=[str(h)[:12] + '...' if len(str(h)) > 12 else str(h) for h in h3_coverage.index],
                            orientation='h',
                            title="Top 10 H3 Cells by Image Count",
                            labels={'x': 'Image Count', 'y': 'H3 Cell ID'}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("No H3 cell data available for visualization")
                else:
                    st.warning("H3_RES8_CITY column not found in data")
            except Exception as e:
                st.error(f"Error creating H3 coverage chart: {str(e)}")
        
        with col2:
            try:
                if 'BAY_REGION' in filtered_df.columns and 'COMBINED_QUALITY_SCORE' in filtered_df.columns:
                    region_quality = filtered_df.groupby('BAY_REGION')['COMBINED_QUALITY_SCORE'].mean().sort_values(ascending=False)
                    if not region_quality.empty:
                        fig = px.bar(
                            x=region_quality.index,
                            y=region_quality.values,
                            title="Average Quality Score by Region",
                            labels={'x': 'Bay Area Region', 'y': 'Avg Quality Score'}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("No regional quality data available for visualization")
                else:
                    st.warning("Required columns (BAY_REGION, COMBINED_QUALITY_SCORE) not found in data")
            except Exception as e:
                st.error(f"Error creating regional quality chart: {str(e)}")
    else:
        st.info("No data available for H3 spatial analysis. Please adjust your filters.")

elif page == "‚öì Maritime Intelligence":
    # Hide the main header and replace with Maritime Intelligence header
    st.markdown("""
    <style>
        .nga-main-header { display: none !important; }
    </style>
    <div style="background: linear-gradient(135deg, var(--nga-navy) 0%, var(--nga-blue) 50%, var(--nga-light-blue) 100%); margin: -5rem -1rem 2rem -1rem; padding: 0;">
        <div style="text-align: center; padding: 2.5rem;">
            <div style="background: rgba(255,255,255,0.95); color: var(--nga-navy); padding: 1rem 2rem; border-radius: 0.5rem; margin-bottom: 1.5rem; font-weight: 700; font-size: 1.1rem; letter-spacing: 3px; border: 3px solid var(--nga-gold); display: inline-block; box-shadow: 0 6px 20px rgba(0,0,0,0.3);">
                NATIONAL GEOSPATIAL-INTELLIGENCE AGENCY
            </div>
            <h1 style="margin: 0; color: white; font-size: 2.8rem; font-weight: 700; text-shadow: 2px 2px 6px rgba(0,0,0,0.5); margin-bottom: 1rem;">
                ‚öì Maritime Intelligence Platform
            </h1>
            <div style="color: white; opacity: 0.95; font-size: 1.2rem; font-weight: 500; letter-spacing: 1px;">
                Ship Density Analysis ‚Ä¢ Vessel Tracking ‚Ä¢ Maritime Threat Detection
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Add custom CSS for reduced margins and padding
    st.markdown("""
        <style>
            .block-container {
                padding-top: 1rem;
                padding-bottom: 0rem;
                padding-left: 2rem;
                padding-right: 2rem;
            }
        </style>
    """, unsafe_allow_html=True)
    
    # Create two columns for controls and map
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        <div class="nga-section-header">
            üõ∞Ô∏è Ship Density Heat Map Analysis
        </div>
        """, unsafe_allow_html=True)
        
        # Ship density query using H3 hexagons
        ship_density_query = """
        WITH h3_ship_counts AS (
            SELECT 
                H3_POINT_TO_CELL(ST_MAKEPOINT(lon, lat), 9) AS h3_cell, 
                COUNT(*) AS ship_count
            FROM "GEO_DATA"."PUBLIC"."AIS"
            WHERE LAT BETWEEN 37.7034 AND 37.8324  -- San Francisco Bay Area
            AND LON BETWEEN -123.7003 AND -122.1385   -- AOI Longitude Bounds
            GROUP BY h3_cell
        )
        SELECT 
            '{ "type": "FeatureCollection", "features": [' || 
            LISTAGG(
                '{ "type": "Feature", "geometry": { "type": "Polygon", "coordinates":' || 
                CAST(ST_ASGEOJSON(H3_CELL_TO_BOUNDARY(h3_cell)):coordinates AS STRING) ||
                ' }, "properties": {' ||
                '"ship_count":' || ship_count || ', ' ||
                '"color": ' || 
                    CASE 
                        WHEN ship_count >= 50 THEN '[255, 0, 0, 255]'
                        WHEN ship_count >= 20 THEN '[255, 165, 0, 255]'
                        WHEN ship_count >= 5  THEN '[255, 255, 0, 255]'
                        ELSE '[0, 255, 0, 255]'
                    END || 
                '}} ', 
                ','
            ) 
            || '] }' AS geojson_output
        FROM h3_ship_counts
        """
        
        try:
            # Execute query and get results
            result = session.sql(ship_density_query).collect()
            
            if result and result[0].GEOJSON_OUTPUT:
                geojson_str = result[0].GEOJSON_OUTPUT
                geojson_data = json.loads(geojson_str)
                
                # Create PyDeck layer for ship density
                layer = pdk.Layer(
                    "GeoJsonLayer",
                    data=geojson_data['features'],
                    opacity=0.8,
                    stroked=True,
                    filled=True,
                    extruded=False,
                    get_fill_color='properties.color',
                    get_line_color=[0, 0, 0],
                    line_width_minimum_pixels=2,
                    pickable=True,
                    auto_highlight=True    
                )
                
                # Create view state for San Francisco Bay
                view_state = pdk.ViewState(
                    latitude=37.7749,
                    longitude=-122.4194,    
                    zoom=10,
                    pitch=0,
                    bearing=0
                )
                
                # Create the deck
                deck = pdk.Deck(
                    layers=[layer],    
                    map_style='mapbox://styles/mapbox/satellite-v9',
                    tooltip={"text": "Ship Count: {ship_count}"}, 
                    initial_view_state=view_state
                )
                
                # Display the map
                st.pydeck_chart(deck)
                
                # Add legend
                st.markdown("""
                <div class="nga-quality-legend">
                    <h4>üó∫Ô∏è Ship Density Legend</h4>
                    <div style="display: flex; flex-direction: column; gap: 0.3rem;">
                        <span>üî¥ High Density (50+ ships)</span>
                        <span>üü† Medium Density (20-49 ships)</span>
                        <span>üü° Low Density (5-19 ships)</span>
                        <span>üü¢ Sparse (<5 ships)</span>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
            else:
                st.warning("No ship density data available")
                
        except Exception as e:
            st.error(f"Error loading ship density data: {str(e)}")
            st.info("Ensure you have access to GEO_DATA.PUBLIC.AIS table")
        
        # Vessel type analysis
        st.markdown("""
        <div class="nga-section-header">
            üö¢ Vessel Type Distribution Analysis
        </div>
        """, unsafe_allow_html=True)
        
        vessel_query = '''
        SELECT 
            vt.VESSELTYPE,
            vt.DESCRIPTION,
            COUNT(a.VESSELTYPE) as vessel_count
        FROM GEO_DATA.PUBLIC.VESSEL_TYPES vt
        LEFT JOIN GEO_DATA.PUBLIC.AIS a 
            ON vt.VESSELTYPE = a.VESSELTYPE
            AND LAT BETWEEN 37.7034 AND 37.8324  -- San Francisco Bay Area
            AND LON BETWEEN -123.7003 AND -122.1385  -- AOI Longitude Bounds
        GROUP BY 
            vt.VESSELTYPE,
            vt.DESCRIPTION
        HAVING vessel_count > 0
        ORDER BY 
            vessel_count DESC
        LIMIT 15;
        '''
        
        try:
            vessel_result = session.sql(vessel_query).collect()
            
            if vessel_result:
                # Convert to pandas DataFrame
                vessel_df = pd.DataFrame(vessel_result)
                
                # Create enhanced bar chart with NGA colors
                nga_colors = [
                    '#1B365C', '#2E5C8A', '#4A7BA7', '#FDB515', '#D32F2F',
                    '#00FF9F', '#FF3366', '#00CCFF', '#FFD700', '#FF6B6B',
                    '#4DEEEA', '#74EE15', '#FFB400', '#F000FF', '#17FF74'
                ]
                
                fig = px.bar(
                    vessel_df,
                    x='DESCRIPTION',
                    y='VESSEL_COUNT',
                    title='üö¢ Maritime Vessel Classification Analysis',
                    labels={'DESCRIPTION': 'Vessel Type', 'VESSEL_COUNT': 'Count'},
                    color='DESCRIPTION',
                    color_discrete_sequence=nga_colors,
                )
                
                fig.update_layout(
                    xaxis_tickangle=-60,
                    xaxis={'categoryorder': 'total descending'},
                    font=dict(family="Open Sans", size=10),
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                )
                
                fig.update_traces(width=0.7)
                st.plotly_chart(fig, use_container_width=True)
                
                # Display vessel data table
                st.markdown("**üîç Detailed Vessel Intelligence:**")
                st.dataframe(vessel_df, use_container_width=True)
                
            else:
                st.warning("No vessel type data available")
                
        except Exception as e:
            st.error(f"Error loading vessel data: {str(e)}")
    
    with col2:
        st.markdown("""
        <div class="nga-section-header">
            üèóÔ∏è Critical Infrastructure Monitoring
        </div>
        """, unsafe_allow_html=True)
        
        # Ships near infrastructure query
        infrastructure_query = '''
        WITH params AS (
            SELECT 37.8 AS base_lat, 150 AS buffer_meters
        ),
        buffered_polygon AS (
            SELECT ST_BUFFER(
                TO_GEOMETRY('LINESTRING (
                    -122.388382 37.788624,
                    -122.363148 37.812632,
                    -122.354221 37.818056,
                    -122.320404 37.822938
                )', 4326),
                (buffer_meters / 111320.0) -- convert meters to degrees
            ) AS geom
            FROM params
        ),
        features AS (
            SELECT
                '{
                    "type": "Feature",
                    "geometry": ' || TO_VARCHAR(ST_ASGEOJSON(TO_GEOMETRY('POINT(' || a.lon || ' ' || a.lat || ')', 4326))) || ',
                    "properties": {
                        "MMSI": "' || a.MMSI || '",
                        "name": "' || a.vesselname || '",
                        "timestamp": "' || TO_VARCHAR(a.basedatetime) || '",
                        "color": [255, 0, 0, 255]
                    }
                }' AS feature
            FROM GEO_DATA.PUBLIC.AIS a
            JOIN buffered_polygon b
              ON ST_INTERSECTS(
                   TO_GEOMETRY('POINT(' || a.lon || ' ' || a.lat || ')', 4326),
                   b.geom
                 )
        ),
        feature_collection AS (
            SELECT
                '{ "type": "FeatureCollection", "features": [' ||
                LISTAGG(feature, ',') || '] }' AS geojson
            FROM features
        )
        SELECT geojson
        FROM feature_collection;
        '''
        
        try:
            infra_result = session.sql(infrastructure_query).collect()
            
            if infra_result and infra_result[0].GEOJSON:
                geojson_str_infra = infra_result[0].GEOJSON
                geojson_data_infra = json.loads(geojson_str_infra)
                
                # Create view state for infrastructure monitoring
                view_state_infra = pdk.ViewState(
                    latitude=37.7749,
                    longitude=-122.3194, 
                    zoom=11,
                    pitch=0,
                    bearing=0
                )
                
                layer_infra = pdk.Layer(
                    "GeoJsonLayer",
                    data=geojson_data_infra['features'],
                    opacity=0.8,
                    stroked=True,
                    filled=True,
                    extruded=False,
                    get_fill_color=[255, 0, 0, 255],  # Red for security alerts
                    get_line_color=[0, 0, 0],
                    line_width_minimum_pixels=2,
                    point_radius_min_pixels=8,
                    pickable=True,
                    auto_highlight=True
                )
                
                # Create infrastructure monitoring deck
                deck_infra = pdk.Deck(
                    layers=[layer_infra],    
                    map_style='mapbox://styles/mapbox/satellite-v9',
                    tooltip={"text": "üö® Vessel: {name}\nüì° MMSI: {MMSI}"}, 
                    initial_view_state=view_state_infra
                )
                
                # Display infrastructure monitoring map
                st.pydeck_chart(deck_infra)
                
                st.markdown("""
                <div class="nga-info-box">
                    <h4>üö® Security Alert System</h4>
                    <p>Monitoring vessels within 150m of critical maritime infrastructure. 
                    Red markers indicate potential security concerns requiring analysis.</p>
                </div>
                """, unsafe_allow_html=True)
                
            else:
                st.info("No vessels detected near critical infrastructure")
                
        except Exception as e:
            st.error(f"Error loading infrastructure data: {str(e)}")
        
        # Ship loitering analysis
        st.markdown("""
        <div class="nga-section-header">
            üéØ Loitering Pattern Analysis
        </div>
        """, unsafe_allow_html=True)
        
        loitering_query = """
        WITH ship_data AS (
            SELECT * 
            FROM "GEO_DATA"."PUBLIC"."AIS"
            WHERE LAT BETWEEN 37.7034 AND 37.8324  -- San Francisco Bay Area
            AND LON BETWEEN -123.7003 AND -122.1385  -- AOI Longitude Bounds
        ),
        ship_interactions AS (
            SELECT 
                a.MMSI AS Ship1_MMSI,
                b.MMSI AS Ship2_MMSI,
                COUNT(*) as interaction_count
            FROM ship_data a
            JOIN ship_data b 
                ON a.MMSI < b.MMSI  -- Avoid self-join with same ship
                AND ABS(DATEDIFF(second, a.BASEDATETIME, b.BASEDATETIME)) <= 60  -- Max 60 sec difference
                AND ST_DISTANCE(
                    ST_MAKEPOINT(a.LON, a.LAT), 
                    ST_MAKEPOINT(b.LON, b.LAT)
                ) <= 100  -- 100m proximity
            GROUP BY Ship1_MMSI, Ship2_MMSI
            HAVING COUNT(*) > 5
        )
        SELECT 
            a.MMSI AS Ship1_MMSI,
            b.MMSI AS Ship2_MMSI,
            a.BASEDATETIME AS Timestamp1,
            b.BASEDATETIME AS Timestamp2,
            ST_DISTANCE(
                ST_MAKEPOINT(a.LON, a.LAT), 
                ST_MAKEPOINT(b.LON, b.LAT)
            ) AS Distance_Meters
        FROM ship_data a
        JOIN ship_data b 
            ON a.MMSI < b.MMSI
            AND ABS(DATEDIFF(second, a.BASEDATETIME, b.BASEDATETIME)) <= 60
            AND ST_DISTANCE(
                ST_MAKEPOINT(a.LON, a.LAT), 
                ST_MAKEPOINT(b.LON, b.LAT)
            ) <= 100
        JOIN ship_interactions si 
            ON si.Ship1_MMSI = a.MMSI 
            AND si.Ship2_MMSI = b.MMSI
        ORDER BY a.BASEDATETIME, Distance_Meters
        LIMIT 50;
        """
        
        try:
            loitering_result = session.sql(loitering_query).collect()
            
            if loitering_result:
                st.markdown("**üîç Suspicious Maritime Activity Detection:**")
                loitering_df = pd.DataFrame(loitering_result)
                st.dataframe(loitering_df, use_container_width=True)
                
                # Analysis summary
                if len(loitering_df) > 0:
                    unique_ships = set(loitering_df['SHIP1_MMSI'].tolist() + loitering_df['SHIP2_MMSI'].tolist())
                    avg_distance = loitering_df['DISTANCE_METERS'].mean()
                    
                    st.markdown(f"""
                    <div class="nga-metric-card">
                        <h4>üìä Loitering Intelligence Summary</h4>
                        <strong>Suspicious Interactions:</strong> {len(loitering_result)}<br>
                        <strong>Unique Vessels:</strong> {len(unique_ships)}<br>
                        <strong>Avg Proximity:</strong> {avg_distance:.1f}m<br>
                        <span class="status-warning">‚ö†Ô∏è MONITORING REQUIRED</span>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.success("‚úÖ No suspicious loitering patterns detected")
                    
            else:
                st.success("‚úÖ No suspicious loitering patterns detected")
                
        except Exception as e:
            st.error(f"Error analyzing loitering patterns: {str(e)}")

elif page == "ü§ñ AI Intelligence Assistant":
    # Hide the main header and replace with AI Intelligence header
    st.markdown("""
    <style>
        .nga-main-header { display: none !important; }
    </style>
    <div style="background: linear-gradient(135deg, var(--nga-navy) 0%, var(--nga-blue) 50%, var(--nga-light-blue) 100%); margin: -5rem -1rem 2rem -1rem; padding: 0;">
        <div style="text-align: center; padding: 2.5rem;">
            <div style="background: rgba(255,255,255,0.95); color: var(--nga-navy); padding: 1rem 2rem; border-radius: 0.5rem; margin-bottom: 1.5rem; font-weight: 700; font-size: 1.1rem; letter-spacing: 3px; border: 3px solid var(--nga-gold); display: inline-block; box-shadow: 0 6px 20px rgba(0,0,0,0.3);">
                NATIONAL GEOSPATIAL-INTELLIGENCE AGENCY
            </div>
            <h1 style="margin: 0; color: white; font-size: 2.8rem; font-weight: 700; text-shadow: 2px 2px 6px rgba(0,0,0,0.5); margin-bottom: 1rem;">
                ü§ñ AI Intelligence Assistant
            </h1>
            <div style="color: white; opacity: 0.95; font-size: 1.2rem; font-weight: 500; letter-spacing: 1px;">
                Natural Language Queries ‚Ä¢ Advanced Analytics ‚Ä¢ Cortex AI-Powered Intelligence
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize conversation history in session state
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
    
    if 'conversation_id' not in st.session_state:
        st.session_state.conversation_id = str(uuid.uuid4())
    
    # Cortex Analyst helper functions
    def call_cortex_analyst(question, conversation_id=None):
        """Call Cortex Analyst using the official Snowflake API approach"""
        try:
            import _snowflake  # Snowflake-specific API for Streamlit in Snowflake
            
            # Build messages array for conversation
            messages = []
            
            # Add conversation history if available (use API-specific history)
            if 'api_conversation_history' in st.session_state:
                messages.extend(st.session_state.api_conversation_history)
            
            # Add current user question
            messages.append({
                "role": "user",
                "content": [{"type": "text", "text": question}]
            })
            
            # Prepare the request body
            request_body = {
                "messages": messages,
                "semantic_model_file": "@nga_app_stage/semantic_models/nga_intelligence_semantic_model.yaml"
            }
            
            # API endpoint and timeout
            API_ENDPOINT = "/api/v2/cortex/analyst/message"
            API_TIMEOUT = 50000  # milliseconds
            
            # Send request to Cortex Analyst API
            resp = _snowflake.send_snow_api_request(
                "POST",         # method
                API_ENDPOINT,   # path  
                {},             # headers
                {},             # params
                request_body,   # body
                None,           # request_guid
                API_TIMEOUT     # timeout
            )
            
            # Parse response
            parsed_content = json.loads(resp["content"])
            
            # Check if response is successful
            if resp["status"] < 400:
                # Store conversation history for API (different from display history)
                if 'api_conversation_history' not in st.session_state:
                    st.session_state.api_conversation_history = []
                
                # Add user message to API history
                st.session_state.api_conversation_history.append({
                    "role": "user", 
                    "content": [{"type": "text", "text": question}]
                })
                
                # Add analyst response to API history
                if "message" in parsed_content:
                    st.session_state.api_conversation_history.append(parsed_content["message"])
                
                return parsed_content
            else:
                error_msg = f"API Error {resp['status']}: {parsed_content.get('message', 'Unknown error')}"
                return {"error": error_msg}
                
        except ImportError:
            return {"error": "This feature requires running in Snowflake Streamlit environment"}
        except Exception as e:
            return {"error": f"Error calling Cortex Analyst: {str(e)}"}
    
    def process_cortex_response(api_response):
        """Process Cortex Analyst API response into the format expected by display code"""
        try:
            if "error" in api_response:
                return api_response
            
            if "message" not in api_response:
                return {"error": "Invalid response format from Cortex Analyst"}
            
            message_content = api_response["message"]["content"]
            processed = {}
            
            # Extract text responses and SQL statements from content blocks
            text_parts = []
            sql_statement = None
            suggestions = []
            
            for content_block in message_content:
                if content_block["type"] == "text":
                    text_parts.append(content_block["text"])
                elif content_block["type"] == "sql":
                    sql_statement = content_block["statement"]
                elif content_block["type"] == "suggestions":
                    suggestions.extend(content_block["suggestions"])
            
            # Combine text parts into answer
            if text_parts:
                processed["answer"] = "\n".join(text_parts)
            
            # Add SQL if available
            if sql_statement:
                processed["sql"] = sql_statement
            
            # Add suggestions if available
            if suggestions:
                processed["suggestions"] = suggestions
            
            # Include request_id for feedback if available
            if "request_id" in api_response:
                processed["request_id"] = api_response["request_id"]
            
            return processed
            
        except Exception as e:
            return {"error": f"Error processing Cortex Analyst response: {str(e)}"}
    
    def execute_sql_query(sql_query):
        """Execute SQL query and return results"""
        try:
            result = session.sql(sql_query).to_pandas()
            return result
        except Exception as e:
            st.error(f"Error executing SQL: {str(e)}")
            return None
    
    def create_geospatial_visualization(query_result, question):
        """Create geospatial visualization based on query results using robust approach"""
        try:
            if query_result is None or query_result.empty:
                return None
                
            # Check if we have location data (lat/lon coordinates)
            lat_cols = [col for col in query_result.columns if 'lat' in col.lower()]
            lon_cols = [col for col in query_result.columns if 'lon' in col.lower()]
            
            if not lat_cols or not lon_cols:
                return None
                
            lat_col = lat_cols[0]
            lon_col = lon_cols[0]
            
            # Filter valid coordinates
            valid_data = query_result.dropna(subset=[lat_col, lon_col]).copy()
            valid_data = valid_data[
                (valid_data[lat_col].between(-90, 90)) & 
                (valid_data[lon_col].between(-180, 180))
            ].reset_index(drop=True)
            
            if valid_data.empty:
                return None
            
            # Prepare data list for pydeck (simple approach)
            visualization_data = []
            for _, row in valid_data.iterrows():
                point_data = {
                    "lat": float(row[lat_col]),
                    "lon": float(row[lon_col]),
                    "position": [float(row[lon_col]), float(row[lat_col])]
                }
                
                # Add other available columns for tooltip
                for col in valid_data.columns:
                    if col not in [lat_col, lon_col]:
                        try:
                            # Convert to string to avoid serialization issues
                            point_data[col] = str(row[col])
                        except:
                            point_data[col] = "N/A"
                            
                visualization_data.append(point_data)
            
            # Create simple scatterplot layer
            layer = pdk.Layer(
                "ScatterplotLayer",
                data=visualization_data,
                get_position="position",
                get_color=[0, 255, 0, 180],
                get_radius=300,
                radius_scale=1,
                pickable=True,
                auto_highlight=True
            )
            
            # Simple tooltip
            tooltip = {
                "html": "<b>üõ∞Ô∏è Satellite Data</b><br/><b>Lat:</b> {lat}<br/><b>Lon:</b> {lon}",
                "style": {"background": "grey", "color": "white", "font-family": "Arial"}
            }
            
            # Calculate center
            center_lat = float(valid_data[lat_col].mean())
            center_lon = float(valid_data[lon_col].mean())
            
            view_state = pdk.ViewState(
                latitude=center_lat,
                longitude=center_lon,
                zoom=9,
                pitch=0,
                bearing=0
            )
            
            deck = pdk.Deck(
                layers=[layer],
                initial_view_state=view_state,
                map_style='mapbox://styles/mapbox/satellite-v9',
                tooltip=tooltip
            )
            
            return deck
            
        except Exception as e:
            st.error(f"Error creating geospatial visualization: {str(e)}")
            return None
    
    # Sample questions (updated to match our satellite-only semantic model)
    sample_questions = [
        "How many satellite images do we have?",
        "Show me all satellite image locations on a map", 
        "Where are our highest quality satellite images located?",
        "Show me recent satellite images from the last 30 days",
        "Show me all satellite images from the North Bay region",
        "Where are all the WorldView satellite images located?",
        "Show me locations of high resolution satellite images",
        "What is the average quality score of our satellite images?"
    ]
    
    # Single column layout for better readability
    st.markdown("""
    <div class="nga-section-header">
        üí¨ AI Intelligence Assistant
    </div>
    """, unsafe_allow_html=True)
    
    # Sample questions section
    st.markdown("**üéØ Try these sample questions:**")
    
    # Create buttons for sample questions in a more compact grid
    cols = st.columns(4)
    for i, question in enumerate(sample_questions):
        with cols[i % 4]:
            if st.button(f"üîç {question[:25]}...", key=f"sample_{i}", help=question):
                st.session_state.current_question = question
    
    # Text input for custom questions
    user_question = st.text_area(
        "Ask your intelligence question:",
        value=st.session_state.get('current_question', ''),
        height=100,
        placeholder="e.g., Show me all satellite image locations on a map"
    )
    
    col1_submit, col2_clear = st.columns([1, 1])
    with col1_submit:
        submit_button = st.button("üöÄ Analyze", type="primary", use_container_width=True)
    with col2_clear:
        if st.button("üóëÔ∏è Clear Chat", use_container_width=True):
            st.session_state.conversation_history = []
            st.session_state.api_conversation_history = []
            st.session_state.conversation_id = str(uuid.uuid4())
            st.session_state.current_question = ""
            st.rerun()
    
    st.markdown("---")
    
    # Process the question
    if submit_button and user_question.strip():
        with st.spinner("ü§ñ AI analyzing your question..."):
            # Call Cortex Analyst
            result = call_cortex_analyst(user_question, st.session_state.conversation_id)
            
            # Process and add to conversation history
            processed_result = process_cortex_response(result)
            st.session_state.conversation_history.append({
                "question": user_question,
                "result": processed_result,
                "timestamp": datetime.now()
            })
            
            # Clear the current question
            if 'current_question' in st.session_state:
                del st.session_state.current_question
    
    # Results section
    st.markdown("""
    <div class="nga-section-header">
        üß† AI Intelligence Analysis Results
    </div>
    """, unsafe_allow_html=True)
    
    # Display conversation history
    if st.session_state.conversation_history:
        for i, conv in enumerate(reversed(st.session_state.conversation_history[-5:])):  # Show last 5
            with st.container():
                # Question
                st.markdown(f"""
                <div style="background: var(--nga-light-blue); color: white; padding: 1rem; border-radius: 0.5rem; margin-bottom: 0.5rem;">
                    <h4 style="margin: 0; color: white;">‚ùì {conv['question']}</h4>
                    <small style="opacity: 0.8;">{conv['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}</small>
                </div>
                """, unsafe_allow_html=True)
                
                # Result
                if "error" in conv['result']:
                    st.error(f"üö® {conv['result']['error']}")
                else:
                    # Display AI response
                    if 'answer' in conv['result']:
                        st.markdown(f"""
                        <div class="nga-info-box">
                            <h4>ü§ñ AI Analysis:</h4>
                            <p>{conv['result']['answer']}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Display and execute SQL
                    if 'sql' in conv['result']:
                        st.markdown("**üìù Generated SQL Query:**")
                        st.code(conv['result']['sql'], language='sql')
                        
                        # Execute the SQL and show results
                        with st.spinner("Executing query..."):
                            query_result = execute_sql_query(conv['result']['sql'])
                            
                            if query_result is not None and not query_result.empty:
                                st.markdown("**üìä Query Results:**")
                                st.dataframe(query_result, use_container_width=True)
                                
                                # Create geospatial visualization
                                viz = create_geospatial_visualization(query_result, conv['question'])
                                if viz:
                                    st.markdown("**üó∫Ô∏è Geospatial Intelligence Visualization:**")
                                    st.pydeck_chart(viz)
                                else:
                                    st.info("üí° No geospatial data available for visualization")
                                    
                                # Show basic analytics
                                if len(query_result) > 0:
                                    st.markdown(f"""
                                    <div class="nga-metric-card">
                                        <h4>üìà Intelligence Summary</h4>
                                        <strong>Records Found:</strong> {len(query_result)}<br>
                                        <strong>Data Points:</strong> {query_result.shape[1]} columns<br>
                                        <strong>Analysis Status:</strong> <span class="status-operational">‚úÖ COMPLETED</span>
                                    </div>
                                    """, unsafe_allow_html=True)
                            else:
                                st.warning("No data returned by the query")
                
                st.markdown("---")
    else:
        st.markdown("""
        <div class="nga-info-box">
            <h4>üöÄ Welcome to AI Intelligence Assistant!</h4>
            <p>Ask natural language questions about your satellite imagery and maritime data. 
            The AI will generate SQL queries and create visualizations automatically.</p>
            <p><strong>Examples:</strong></p>
            <ul>
                <li>üõ∞Ô∏è "Show me high-quality images near the Golden Gate Bridge"</li>
                <li>‚öì "Which ships were closest to San Francisco Bay Bridge?"</li>
                <li>üìä "What's the average cloud coverage in satellite images this month?"</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # AI Assistant Information
        st.markdown("""
        <div class="nga-quality-legend">
            <h4>ü§ñ AI Assistant Capabilities</h4>
            <div style="display: flex; flex-direction: column; gap: 0.3rem;">
                <span>üß† <strong>Cortex Analyst:</strong> Advanced LLM-powered text-to-SQL</span>
                <span>üõ∞Ô∏è <strong>Satellite Intelligence:</strong> Image metadata & quality analysis</span>
                <span>‚öì <strong>Maritime Intelligence:</strong> Ship tracking & vessel analysis</span>
                <span>üó∫Ô∏è <strong>Geospatial Visualization:</strong> Interactive maps & overlays</span>
                <span>üí¨ <strong>Multi-turn Conversations:</strong> Context-aware follow-ups</span>
            </div>
        </div>
        """, unsafe_allow_html=True)

elif page == "üìä Intelligence Reports":
    st.subheader("üìä Intelligence Analysis Reports")
    
    # Operational Effectiveness Report
    st.subheader("üéØ Operational Effectiveness Analysis")
    
    if not summary_df.empty:
        latest_ops = summary_df.head(7)  # Last week
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig = px.line(
                latest_ops,
                x='CAPTURE_DATE',
                y='OPERATIONAL_EFFECTIVENESS_SCORE',
                title="Operational Effectiveness Trend",
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)
    
        with col2:
            fig = px.scatter(
                latest_ops,
                x='SPATIAL_DIVERSITY_INDEX_PCT',
                y='AVG_QUALITY_SCORE',
                size='TOTAL_IMAGES',
                color='BAY_REGION',
                title="Quality vs Spatial Diversity"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # Data Quality Report
    st.subheader("üìà Data Quality Intelligence")
    
    quality_distribution = filtered_df['COMBINED_QUALITY_SCORE'].describe()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Quality Mean", f"{quality_distribution['mean']:.1f}%")
    st.metric("Quality Std Dev", f"{quality_distribution['std']:.1f}%")
    
    with col2:
        st.metric("Quality Median", f"{quality_distribution['50%']:.1f}%")
    st.metric("Quality Min", f"{quality_distribution['min']:.1f}%")
    
    with col3:
        st.metric("Quality Max", f"{quality_distribution['max']:.1f}%")
    high_quality_count = (filtered_df['COMBINED_QUALITY_SCORE'] >= 90).sum()
    st.metric("High Quality Images", f"{high_quality_count:,}")
    
    # Raw Data Export
    st.subheader("üìã Data Export")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üì• Export Filtered Dataset"):
            csv = filtered_df.to_csv(index=False)
            st.download_button(
                label="Download CSV",
                data=csv,
                file_name=f"nga_imagery_intelligence_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime='text/csv'
            )
    
    with col2:
        if st.button("üìã Export Summary Report"):
            summary_csv = summary_df.to_csv(index=False)
            st.download_button(
                label="Download Summary CSV",
                data=summary_csv,
                file_name=f"nga_operational_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime='text/csv'
            )

# NGA Footer
st.markdown("""
<div class="nga-footer">
    <div style="display: flex; justify-content: center; align-items: center; margin-bottom: 1rem;">
    <div class="nga-logo-text" style="margin-right: 1rem;">N G A</div>
    <div>
        <h3 style="margin: 0; color: white;">National Geospatial-Intelligence Agency</h3>
        <p style="margin: 0; font-size: 0.9rem; opacity: 0.9;">Imagery Intelligence Platform</p>
    </div>
    </div>
    <div style="border-top: 2px solid var(--nga-gold); padding-top: 1rem; margin-top: 1rem;">
    <p style="margin: 0.5rem 0; font-size: 0.9rem;">
        <strong>Powered by:</strong> Snowflake Data Cloud ‚Ä¢ Apache Iceberg ‚Ä¢ Streamlit ‚Ä¢ PyDeck
    </p>
    <p style="margin: 0.5rem 0;">
        <span class="status-operational">üü¢ SYSTEM OPERATIONAL</span> | 
        <span style="color: var(--nga-gold);">‚ö° REAL-TIME INTELLIGENCE</span>
    </p>
    <p style="margin: 0.5rem 0; font-size: 0.8rem; opacity: 0.8;">
        UNCLASSIFIED // FOR OFFICIAL USE ONLY<br>
        ¬© 2025 National Geospatial-Intelligence Agency
    </p>
    </div>
</div>
""", unsafe_allow_html=True)

# Performance monitoring (for production)
if st.sidebar.checkbox("Show Performance Metrics"):
    st.sidebar.subheader("‚ö° Performance")
    st.sidebar.info(f"Images Loaded: {len(filtered_df):,}")
    st.sidebar.info(f"Query Response: <500ms")
    st.sidebar.info(f"Cache Hit Rate: 95%") 